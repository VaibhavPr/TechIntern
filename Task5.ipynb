{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport string\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Embedding, Bidirectional, TimeDistributed\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-10T16:21:10.747456Z","iopub.execute_input":"2023-06-10T16:21:10.747840Z","iopub.status.idle":"2023-06-10T16:21:10.754124Z","shell.execute_reply.started":"2023-06-10T16:21:10.747808Z","shell.execute_reply":"2023-06-10T16:21:10.752918Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\")\ndf.columns = ['en', 'fr']\ndf.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:21:17.518966Z","iopub.execute_input":"2023-06-10T16:21:17.519727Z","iopub.status.idle":"2023-06-10T16:21:18.066112Z","shell.execute_reply.started":"2023-06-10T16:21:17.519686Z","shell.execute_reply":"2023-06-10T16:21:18.065013Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.iloc[:20]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:38:29.872309Z","iopub.execute_input":"2023-06-10T16:38:29.873349Z","iopub.status.idle":"2023-06-10T16:38:29.888272Z","shell.execute_reply.started":"2023-06-10T16:38:29.873294Z","shell.execute_reply":"2023-06-10T16:38:29.887290Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"        en             fr clean_en      clean_fr\n0      Hi.         Salut!       hi         salut\n1     Run!        Cours !      run        cours \n2     Run!       Courez !      run       courez \n3     Who?          Qui ?      who          qui \n4     Wow!     Ça alors !      wow     ça alors \n5    Fire!       Au feu !     fire       au feu \n6    Help!     À l'aide !     help     à l'aide \n7    Jump.         Saute.     jump         saute\n8    Stop!    Ça suffit !     stop    ça suffit \n9    Stop!         Stop !     stop         stop \n10   Stop!   Arrête-toi !     stop   arrête-toi \n11   Wait!      Attends !     wait      attends \n12   Wait!     Attendez !     wait     attendez \n13  Go on.      Poursuis.    go on      poursuis\n14  Go on.     Continuez.    go on     continuez\n15  Go on.    Poursuivez.    go on    poursuivez\n16  Hello!      Bonjour !    hello      bonjour \n17  Hello!        Salut !    hello        salut \n18  I see.  Je comprends.    i see  je comprends\n19  I try.      J'essaye.    i try      j'essaye","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n      <th>clean_en</th>\n      <th>clean_fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n      <td>hi</td>\n      <td>salut</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n      <td>run</td>\n      <td>cours</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n      <td>run</td>\n      <td>courez</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n      <td>who</td>\n      <td>qui</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n      <td>wow</td>\n      <td>ça alors</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n      <td>fire</td>\n      <td>au feu</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Help!</td>\n      <td>À l'aide !</td>\n      <td>help</td>\n      <td>à l'aide</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jump.</td>\n      <td>Saute.</td>\n      <td>jump</td>\n      <td>saute</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Stop!</td>\n      <td>Ça suffit !</td>\n      <td>stop</td>\n      <td>ça suffit</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Stop!</td>\n      <td>Stop !</td>\n      <td>stop</td>\n      <td>stop</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Stop!</td>\n      <td>Arrête-toi !</td>\n      <td>stop</td>\n      <td>arrête-toi</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Wait!</td>\n      <td>Attends !</td>\n      <td>wait</td>\n      <td>attends</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Wait!</td>\n      <td>Attendez !</td>\n      <td>wait</td>\n      <td>attendez</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Go on.</td>\n      <td>Poursuis.</td>\n      <td>go on</td>\n      <td>poursuis</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Go on.</td>\n      <td>Continuez.</td>\n      <td>go on</td>\n      <td>continuez</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Go on.</td>\n      <td>Poursuivez.</td>\n      <td>go on</td>\n      <td>poursuivez</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Hello!</td>\n      <td>Bonjour !</td>\n      <td>hello</td>\n      <td>bonjour</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Hello!</td>\n      <td>Salut !</td>\n      <td>hello</td>\n      <td>salut</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>I see.</td>\n      <td>Je comprends.</td>\n      <td>i see</td>\n      <td>je comprends</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>I try.</td>\n      <td>J'essaye.</td>\n      <td>i try</td>\n      <td>j'essaye</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"custom_punct = string.punctuation.replace(\"-\",\"\").replace(\"'\",\"\")\ndef clean(text):\n    text = text.lower()\n    text = re.sub(\"[\"+custom_punct+\"]\", \"\", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:34:10.392918Z","iopub.execute_input":"2023-06-10T16:34:10.393300Z","iopub.status.idle":"2023-06-10T16:34:10.400010Z","shell.execute_reply.started":"2023-06-10T16:34:10.393266Z","shell.execute_reply":"2023-06-10T16:34:10.398678Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df[\"clean_en\"] = df[\"en\"].apply(clean)\ndf[\"clean_fr\"] = df[\"fr\"].apply(clean)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:21:18.162677Z","iopub.execute_input":"2023-06-10T16:21:18.163071Z","iopub.status.idle":"2023-06-10T16:21:19.346005Z","shell.execute_reply.started":"2023-06-10T16:21:18.163032Z","shell.execute_reply":"2023-06-10T16:21:19.344872Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df[\"clean_en\"], df[\"clean_fr\"], test_size=0.2)\nen_tokenizer = Tokenizer()\nfr_tokenizer = Tokenizer()\n\nen_tokenizer.fit_on_texts(X_train)\nfr_tokenizer.fit_on_texts(y_train)\ninput_vocab_size = len(en_tokenizer.index_word) + 1\noutput_vocab_size = len(fr_tokenizer.index_word) + 1\nX_train_sequences = en_tokenizer.texts_to_sequences(X_train)\nX_test_sequences = en_tokenizer.texts_to_sequences(X_test)\n\ny_train_sequences = fr_tokenizer.texts_to_sequences(y_train)\ny_test_sequences = fr_tokenizer.texts_to_sequences(y_test)\nmaxlen = 55 # max length of all sentences (EN: 48, FR: 55)\nX_train_pad = pad_sequences(X_train_sequences, maxlen=maxlen, truncating='post', padding=\"post\")\nX_test_pad = pad_sequences(X_test_sequences, maxlen=maxlen, truncating='post', padding=\"post\")\n\ny_train_pad = pad_sequences(y_train_sequences, maxlen=maxlen, truncating='post', padding=\"post\")\ny_test_pad = pad_sequences(y_test_sequences, maxlen=maxlen, truncating='post', padding=\"post\")\n\ny_train_pad = y_train_pad.reshape(*y_train_pad.shape, 1)\ny_test_pad = y_test_pad.reshape(*y_test_pad.shape, 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:21:19.347891Z","iopub.execute_input":"2023-06-10T16:21:19.348306Z","iopub.status.idle":"2023-06-10T16:21:32.214361Z","shell.execute_reply.started":"2023-06-10T16:21:19.348264Z","shell.execute_reply":"2023-06-10T16:21:32.213161Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = tf.keras.Sequential(\n            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n        )\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'att': self.att,\n            'ffn': self.ffn,\n            'layernorm1': self.layernorm1,\n            'layernorm2': self.layernorm2,\n            'dropout1': self.dropout1,\n            'dropout2': self.dropout2,\n        })\n        return config\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n    \nclass TokenAndPositionEmbedding(tf.keras.layers.Layer):\n    \n    def __init__(self, maxlen, vocab_size, embed_dim):\n        super(TokenAndPositionEmbedding, self).__init__()\n        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n        \n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'token_emb': self.token_emb,\n            'pos_emb': self.pos_emb,\n        })\n        return config\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        x = self.token_emb(x)\n        return x + positions","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:21:32.218411Z","iopub.execute_input":"2023-06-10T16:21:32.218738Z","iopub.status.idle":"2023-06-10T16:21:32.236317Z","shell.execute_reply.started":"2023-06-10T16:21:32.218709Z","shell.execute_reply":"2023-06-10T16:21:32.235292Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"num_heads = 3  # Number of attention heads\nff_dim = 32  # Hidden layer size in feed forward network inside transformer\nembedding_dim = 200\nadam = Adam(learning_rate=0.003)\n\n\ninputs = tf.keras.layers.Input(shape=(maxlen,))\nembedding_layer = TokenAndPositionEmbedding(maxlen, input_vocab_size, embedding_dim)\nx = embedding_layer(inputs)\ntransformer_block = TransformerBlock(embedding_dim, num_heads, ff_dim)\nx = transformer_block(x)\nx = TimeDistributed(Dense(256, activation=\"relu\"))(x)\noutputs = TimeDistributed(Dense(output_vocab_size, activation=\"softmax\"))(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss=sparse_categorical_crossentropy, optimizer=adam, metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:21:32.237856Z","iopub.execute_input":"2023-06-10T16:21:32.238850Z","iopub.status.idle":"2023-06-10T16:21:36.549838Z","shell.execute_reply.started":"2023-06-10T16:21:32.238809Z","shell.execute_reply":"2023-06-10T16:21:36.548636Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 55)]              0         \n_________________________________________________________________\ntoken_and_position_embedding (None, 55, 200)           2718600   \n_________________________________________________________________\ntransformer_block (Transform (None, 55, 200)           495832    \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 55, 256)           51456     \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 55, 28130)         7229410   \n=================================================================\nTotal params: 10,495,298\nTrainable params: 10,495,298\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fit model\nhistory = model.fit(X_train_pad,\n                    y_train_pad,\n                    validation_data=(X_test_pad, y_test_pad),\n                    verbose=1,\n                    batch_size=128,\n                    epochs=3,\n                   )","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:49:40.772603Z","iopub.execute_input":"2023-06-10T16:49:40.773222Z","iopub.status.idle":"2023-06-10T17:08:02.789628Z","shell.execute_reply.started":"2023-06-10T16:49:40.773184Z","shell.execute_reply":"2023-06-10T17:08:02.788218Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/3\n1098/1098 [==============================] - 360s 328ms/step - loss: 0.3820 - accuracy: 0.9199 - val_loss: 0.3931 - val_accuracy: 0.9203\nEpoch 2/3\n1098/1098 [==============================] - 358s 326ms/step - loss: 0.3380 - accuracy: 0.9235 - val_loss: 0.3834 - val_accuracy: 0.9217\nEpoch 3/3\n1098/1098 [==============================] - 357s 325ms/step - loss: 0.3103 - accuracy: 0.9265 - val_loss: 0.3786 - val_accuracy: 0.9217\n","output_type":"stream"}]},{"cell_type":"code","source":"samples = [\n    \"I am doing a project given by TechIntern\",\n    \"How are you\",\n    \"This is a task.\",\n    \"Prepared a English to French translation website\"\n]\nfor sample in samples:\n    pred = model.predict([pad_sequences(en_tokenizer.texts_to_sequences([sample]), maxlen=maxlen, padding='post', truncating='post')])[0].argmax(axis=1)\n    output_text = fr_tokenizer.sequences_to_texts([pred])[0]\n    print(\"EN: \" + sample)\n    print(\"FR: \" + output_text)\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T17:15:00.472990Z","iopub.execute_input":"2023-06-10T17:15:00.473412Z","iopub.status.idle":"2023-06-10T17:15:00.793533Z","shell.execute_reply.started":"2023-06-10T17:15:00.473373Z","shell.execute_reply":"2023-06-10T17:15:00.792340Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"EN: I am doing a project given by TechIntern\nFR: je fais un un projet à\n\nEN: How are you\nFR: comment es tu\n\nEN: This is a task.\nFR: c'est une d'une tâche\n\nEN: Prepared a English to French translation website\nFR: préparé un anglais à améliorer français le\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"MachineTrans.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:37:34.333210Z","iopub.execute_input":"2023-06-10T16:37:34.333768Z","iopub.status.idle":"2023-06-10T16:37:34.647333Z","shell.execute_reply.started":"2023-06-10T16:37:34.333727Z","shell.execute_reply":"2023-06-10T16:37:34.646208Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Code for creating website\nfrom flask import Flask, render_template, request\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/translate', methods=['POST'])\ndef translate():\n    text = request.form['text']\n    translation = translate_text(text, model)\n    return render_template('translation.html', translation=translation)\n\nif __name__ == '__main__':\n    app.run()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:35:29.220922Z","iopub.execute_input":"2023-06-10T16:35:29.221356Z","iopub.status.idle":"2023-06-10T16:37:34.331220Z","shell.execute_reply.started":"2023-06-10T16:35:29.221319Z","shell.execute_reply":"2023-06-10T16:37:34.330099Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":" * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"}]},{"cell_type":"code","source":"#Content of index.html\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Translation Website</title>\n</head>\n<body>\n    <h1>English to French Translation</h1>\n    <form action=\"/translate\" method=\"post\">\n        <textarea name=\"text\" rows=\"4\" cols=\"50\"></textarea><br>\n        <input type=\"submit\" value=\"Translate\">\n    </form>\n</body>\n</html>\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Content of translation.html:\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Translation Result</title>\n</head>\n<body>\n    <h1>Translation Result</h1>\n    <p>{{ translation }}</p>\n</body>\n</html>\n","metadata":{},"execution_count":null,"outputs":[]}]}